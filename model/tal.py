import torch
import torch.nn as nn




class TaskAlignedAssigner(nn.Module):
    """A task-aligned assigner for object detection.

    This class assigns ground-truth (gt) objects to anchors based on the task-aligned metric, which combines both
    classification and localization information.

    Attributes:
        topk (int): The number of top candidates to consider.
        num_classes (int): The number of object classes.
        alpha (float): The alpha parameter for the classification component of the task-aligned metric.
        beta (float): The beta parameter for the localization component of the task-aligned metric.
        eps (float): A small value to prevent division by zero.
    """

    def __init__(self, topk: int = 13, num_classes: int = 80, alpha: float = 1.0, beta: float = 6.0, eps: float = 1e-9):
        """Initialize a TaskAlignedAssigner object with customizable hyperparameters.

        Args:
            topk (int, optional): The number of top candidates to consider.
            num_classes (int, optional): The number of object classes.
            alpha (float, optional): The alpha parameter for the classification component of the task-aligned metric.
            beta (float, optional): The beta parameter for the localization component of the task-aligned metric.
            eps (float, optional): A small value to prevent division by zero.
        """
        super().__init__()
        self.topk = topk
        self.num_classes = num_classes
        self.alpha = alpha
        self.beta = beta
        self.eps = eps

    @torch.no_grad()
    def forward(self, pd_scores, pd_circles, anc_points, gt_labels, gt_bboxes, mask_gt):
        """Compute the task-aligned assignment.

        Args:
            pd_scores (torch.Tensor): Predicted classification scores with shape (bs, num_total_anchors, num_classes).
            pd_circles (torch.Tensor): Predicted circles with shape (bs, num_total_anchors, 4).
            anc_points (torch.Tensor): Anchor points with shape (num_total_anchors, 2).
            gt_labels (torch.Tensor): Ground truth labels with shape (bs, n_max_boxes, 1).
            gt_bboxes (torch.Tensor): Ground truth boxes with shape (bs, n_max_boxes, 4).
            mask_gt (torch.Tensor): Mask for valid ground truth boxes with shape (bs, n_max_boxes, 1).

        Returns:
            target_labels (torch.Tensor): Target labels with shape (bs, num_total_anchors).
            target_bboxes (torch.Tensor): Target bounding boxes with shape (bs, num_total_anchors, 4).
            target_scores (torch.Tensor): Target scores with shape (bs, num_total_anchors, num_classes).
            fg_mask (torch.Tensor): Foreground mask with shape (bs, num_total_anchors).
            target_gt_idx (torch.Tensor): Target ground truth indices with shape (bs, num_total_anchors).

        References:
            https://github.com/Nioolek/PPYOLOE_pytorch/blob/master/ppyoloe/assigner/tal_assigner.py
        """
        self.bs = pd_scores.shape[0]
        self.n_max_boxes = gt_bboxes.shape[1]
        device = gt_bboxes.device

        if self.n_max_boxes == 0:
            return (
                torch.full_like(pd_scores[..., 0], self.num_classes),
                torch.zeros_like(pd_circles),
                torch.zeros_like(pd_scores),
                torch.zeros_like(pd_scores[..., 0]),
                torch.zeros_like(pd_scores[..., 0]),
            )

        try:
            return self._forward(pd_scores, pd_circles, anc_points, gt_labels, gt_bboxes, mask_gt)
        except torch.cuda.OutOfMemoryError:
            # Move tensors to CPU, compute, then move back to original device
            #LOGGER.warning("CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU")
            cpu_tensors = [t.cpu() for t in (pd_scores, pd_circles, anc_points, gt_labels, gt_bboxes, mask_gt)]
            result = self._forward(*cpu_tensors)
            return tuple(t.to(device) for t in result)


    def _forward(self, pd_scores, pd_circles, anc_points, gt_labels, gt_circles, mask_gt):
        """Compute the task-aligned assignment.

        Args:
            pd_scores (torch.Tensor): Predicted classification scores with shape (bs, num_total_anchors, num_classes).
            pd_circles (torch.Tensor): Predicted circles with shape (bs, num_total_anchors, 3).
            anc_points (torch.Tensor): Anchor points with shape (num_total_anchors, 2).
            gt_labels (torch.Tensor): Ground truth labels with shape (bs, n_max_boxes, 1).
            gt_circles (torch.Tensor): Ground truth circles with shape (bs, n_max_boxes, 3).
            mask_gt (torch.Tensor): Mask for valid ground truth circles with shape (bs, n_max_boxes, 1).

        Returns:
            target_labels (torch.Tensor): Target labels with shape (bs, num_total_anchors).
            target_circles (torch.Tensor): Target circles with shape (bs, num_total_anchors, 3).
            target_scores (torch.Tensor): Target scores with shape (bs, num_total_anchors, num_classes).
            fg_mask (torch.Tensor): Foreground mask with shape (bs, num_total_anchors).
            target_gt_idx (torch.Tensor): Target ground truth indices with shape (bs, num_total_anchors).
        """
        mask_pos, align_metric, overlaps, distence= self.get_pos_mask(
            pd_scores, pd_circles, gt_labels, gt_circles, anc_points, mask_gt
        )  # mask_pos ä¸çœŸå®æ¡†åŒ¹é…çš„topkä¸ªå…ˆéªŒæ¡†çš„maskï¼Œå½¢çŠ¶ä¸º(bs, max_num_obj, h*w)ï¼›
        # align_metric ä¸ºçœŸå®æ¡†ä¸å…ˆéªŒæ¡†çš„å¯¹é½åº¦é‡ï¼Œå½¢çŠ¶ä¸º(bs, max_num_obj, h*w)ï¼›
        # overlaps ä¸ºé¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„iouï¼Œå½¢çŠ¶ä¸º(bs, max_num_obj, h*w)ï¼›
        # distence ä¸ºé¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„è·ç¦»ï¼Œå½¢çŠ¶ä¸º(bs, max_num_obj, h*w)ï¼›

        # é€‰å‡ºtopkä¸ªå…ˆéªŒæ¡†ä¸­æœ€é«˜å¾—åˆ†çš„çš„ä¸‹æ ‡å’Œæ©ç 
        target_gt_idx, fg_mask, mask_pos = self.select_highest_overlaps(mask_pos, overlaps, self.n_max_boxes)
        # Assigned target
        target_labels, target_circles, target_scores = self.get_targets(gt_labels, gt_circles, target_gt_idx, fg_mask)
        # Normalize
        align_metric *= mask_pos
        pos_align_metrics = align_metric.amax(dim=-1, keepdim=True)  # b, max_num_obj
        pos_overlaps = (overlaps * mask_pos).amax(dim=-1, keepdim=True)  # b, max_num_obj
        norm_align_metric = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2).unsqueeze(-1)
        target_scores = target_scores * norm_align_metric
        return target_labels, target_circles, target_scores, fg_mask.bool(), target_gt_idx










    def get_pos_mask(self, pd_scores, pd_circles, gt_labels, gt_circles, anc_points, mask_gt):
        """Get positive mask for each ground truth circle.

        Args:
            pd_scores (torch.Tensor): Predicted classification scores with shape (bs, num_total_anchors, num_classes).
            pd_circles (torch.Tensor): Predicted circles with shape (bs, num_total_anchors, 3).
            gt_labels (torch.Tensor): Ground truth labels with shape (bs, n_max_boxes, 1).
            gt_circles (torch.Tensor): Ground truth circles with shape (bs, n_max_boxes, 3).
            anc_points (torch.Tensor): Anchor points with shape (num_total_anchors, 2).
            mask_gt (torch.Tensor): Mask for valid ground truth circles with shape (bs, n_max_boxes, 1).

        Returns:
            mask_pos (torch.Tensor): Positive mask with shape (bs, max_num_obj, h*w).
            align_metric (torch.Tensor): Alignment metric with shape (bs, max_num_obj, h*w).
            overlaps (torch.Tensor): Overlaps between predicted vs ground truth boxes with shape (bs, max_num_obj, h*w).
        """
        mask_in_gts = self.select_candidates_in_gts(anc_points, gt_circles)  # æ‰¾å‡ºçœŸå®æ¡†å†…çš„é”šç‚¹ï¼ˆæ©ç ï¼‰ï¼ˆ8, max_objects, 2550000ï¼‰
        # Get anchor_align metric, (b, max_num_obj, h*w)
        align_metric, overlaps, distence = self.get_box_metrics(pd_scores, pd_circles, gt_labels, gt_circles, mask_in_gts * mask_gt)
        # Get topk_metric mask, (b, max_num_obj, h*w)
        mask_topk = self.select_topk_candidates(align_metric, topk_mask=mask_gt.expand(-1, -1, self.topk).bool())
        mask_pos = mask_topk * mask_in_gts * mask_gt
        return mask_pos, align_metric, overlaps, distence




    def get_box_metrics(self, pd_scores, pd_circles, gt_labels, gt_circles, mask_gt):
        """Compute alignment metric given predicted and ground truth circles.æ ¹æ®é¢„æµ‹å’ŒçœŸå®çš„åœ†è®¡ç®—å¯¹é½åº¦é‡

        Args:
            pd_scores (torch.Tensor): Predicted classification scores with shape (bs, num_total_anchors, num_classes).
            pd_circles (torch.Tensor): Predicted circles with shape (bs, num_total_anchors, 3).
            gt_labels (torch.Tensor): Ground truth labels with shape (bs, n_max_boxes, 1).
            gt_circles (torch.Tensor): Ground truth circles with shape (bs, n_max_boxes, 3).
            mask_gt (torch.Tensor): Mask for valid ground truth circles with shape (bs, n_max_boxes, 2550000).

        Returns:
            align_metric (torch.Tensor): Alignment metric combining classification and localization.
            overlaps (torch.Tensor): IoU overlaps between predicted and ground truth boxes.
        """
        na = pd_circles.shape[-2] #2550000
        mask_gt = mask_gt.bool()  # b, max_num_obj, h*w
        overlaps = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_circles.dtype, device=pd_circles.device)#GTä¸é¢„æµ‹æ¡†çš„IOU[bs,max_objects,2550000]
        distence = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_circles.dtype, device=pd_circles.device)
        circles_scores = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_scores.dtype, device=pd_scores.device)#é¢„æµ‹æ¡†å¾—åˆ†[bs,max_objects,2550000]

        ind = torch.zeros([2, self.bs, self.n_max_boxes], dtype=torch.long)  # 2, b, max_num_obj
        ind[0] = torch.arange(end=self.bs).view(-1, 1).expand(-1, self.n_max_boxes)  # b, max_num_objï¼ˆè¡¨ç¤ºæ‰¹æ¬¡ç´¢å¼•ï¼‰
        ind[1] = gt_labels.squeeze(-1)  # b, max_num_objï¼ˆè¡¨ç¤ºçœŸå®æ¡†çš„ç±»åˆ«ï¼‰
        # Get the scores of each grid for each gt cls
        circles_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w

        # (b, max_num_obj, 1, 4), (b, 1, h*w, 4)
        pd_circles = pd_circles.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]#(bs,max_objects,2550000,3)*mask_gt->(bs*max_objects*2550000,3)
        gt_circles = gt_circles.unsqueeze(2).expand(-1, -1, na, -1)[mask_gt]#(bs,max_objects,2550000,3)*mask_gt->(bs*max_objects*2550000,3)
        overlaps[mask_gt] = circle_ious(gt_circles, pd_circles,na)#(bs,max_objects,2550000) è®¡ç®—çœŸå®åœ†ä¸é¢„æµ‹åœ†çš„IOU
        distence[mask_gt] = center_distanceLoss(gt_circles, pd_circles,na)#(bs,max_objects,2550000) è®¡ç®—çœŸå®åœ†ä¸é¢„æµ‹åœ†åœ†å¿ƒçš„è·ç¦»

        align_metric = circles_scores.pow(self.alpha) * overlaps.pow(self.beta) * distence.pow(self.beta)
        return align_metric, overlaps, distence #(bs,max_objects,2550000) å¯¹é½åº¦é‡  (bs,max_objects,2550000) IOU (bs,max_objects,2550000) ä¸­å¿ƒè·ç¦»æŸå¤±



    def select_topk_candidates(self, metrics, topk_mask=None):
        """Select the top-k candidates based on the given metrics.

        Args:
            metrics (torch.Tensor): A tensor of shape (b, max_num_obj, h*w), where b is the batch size, max_num_obj is
                the maximum number of objects, and h*w represents the total number of anchor points.
            topk_mask (torch.Tensor, optional): An optional boolean tensor of shape (b, max_num_obj, topk), where topk
                is the number of top candidates to consider. If not provided, the top-k values are automatically
                computed based on the given metrics.

        Returns:
            (torch.Tensor): A tensor of shape (b, max_num_obj, h*w) containing the selected top-k candidates.
        """
        # (b, max_num_obj, topk)  ä»255000ä¸ªé”šç‚¹ä¸­é€‰æ‹©topkä¸ªå¾—åˆ†æœ€é«˜çš„é”šç‚¹
        topk_metrics, topk_idxs = torch.topk(metrics, self.topk, dim=-1, largest=True)
        if topk_mask is None:
            topk_mask = (topk_metrics.max(-1, keepdim=True)[0] > self.eps).expand_as(topk_idxs)
        # (b, max_num_obj, topk)
        topk_idxs.masked_fill_(~topk_mask, 0)

        # (b, max_num_obj, topk, h*w) -> (b, max_num_obj, h*w)
        count_tensor = torch.zeros(metrics.shape, dtype=torch.int8, device=topk_idxs.device)
        ones = torch.ones_like(topk_idxs[:, :, :1], dtype=torch.int8, device=topk_idxs.device)#[b,max_objects,1]
        for k in range(self.topk):#å¯¹äºæ¯ä¸ªçœŸå®ç›®æ ‡ï¼Œæ‰¾åˆ°å…¶ç¬¬ kå¥½çš„å€™é€‰é”šç‚¹åœ¨ h*wä¸­çš„ä½ç½®ï¼Œç„¶ååœ¨ count_tensorçš„å¯¹åº”ä½ç½®ä¸ŠåŠ  1ã€‚
            count_tensor.scatter_add_(-1, topk_idxs[:, :, k : k + 1], ones)
        # Filter invalid bboxes
        count_tensor.masked_fill_(count_tensor > 1, 0)#masked_fill_æ“ä½œå°†æ‰€æœ‰è®¡æ•°å¤§äº 1 çš„ä½ç½®é‡ç½®ä¸º 0ã€‚
                                                            # è¿™ä¸€æ­¥ç¡®ä¿äº†æ¯ä¸ªé”šç‚¹å¯¹äºåŒä¸€ä¸ªçœŸå®ç›®æ ‡æœ€å¤šåªè¢«è®¡ç®—ä¸€æ¬¡ï¼Œé˜²å¾¡æ€§ç¼–ç¨‹

        return count_tensor.to(metrics.dtype)#å°† count_tensorçš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºä¸è¾“å…¥ metricsä¸€è‡´åè¿”å›ã€‚


    def get_targets(self, gt_labels, gt_circles, target_gt_idx, fg_mask):
        """Compute target labels, target circles, and target scores for the positive anchor points.

        Args:
            gt_labels (torch.Tensor): Ground truth labels of shape (b, max_num_obj, 1), where b is the batch size and
                max_num_obj is the maximum number of objects.
            gt_circles (torch.Tensor): Ground truth circles of shape (b, max_num_obj, 3).
            target_gt_idx (torch.Tensor): Indices of the assigned ground truth objects for positive anchor points, with
                shape (b, h*w), where h*w is the total number of anchor points.
            fg_mask (torch.Tensor): A boolean tensor of shape (b, h*w) indicating the positive (foreground) anchor
                points.

        Returns:
            target_labels (torch.Tensor): Target labels for positive anchor points with shape (b, h*w).
            target_circles (torch.Tensor): Target circles for positive anchor points with shape (b, h*w, 3).
            target_scores (torch.Tensor): Target scores for positive anchor points with shape (b, h*w, num_classes).
        """
        # Assigned target labels, (b, 1)
        batch_ind = torch.arange(end=self.bs, dtype=torch.int64, device=gt_labels.device)[..., None]
        target_gt_idx = target_gt_idx + batch_ind * self.n_max_boxes  # (b, h*w)
        target_labels = gt_labels.long().flatten()[target_gt_idx]  # (b, h*w)

        # Assigned target circles, (b, max_num_obj, 3) -> (b, h*w, 3)
        target_circles = gt_circles.view(-1, gt_circles.shape[-1])[target_gt_idx]

        # Assigned target scores
        target_labels.clamp_(0)

        # 10x faster than F.one_hot()
        target_scores = torch.zeros(
            (target_labels.shape[0], target_labels.shape[1], self.num_classes),
            dtype=torch.int64,
            device=target_labels.device,
        )  # (b, h*w, 80)
        target_scores.scatter_(2, target_labels.unsqueeze(-1), 1)

        fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  # (b, h*w, 80)
        target_scores = torch.where(fg_scores_mask > 0, target_scores, 0)

        return target_labels, target_circles, target_scores
        # target_labelsï¼šæ­£æ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾ï¼ˆå½¢çŠ¶(b, h * w)ï¼‰
        # target_circlesï¼šæ­£æ ·æœ¬å¯¹åº”çš„çœŸå®æ¡†åæ ‡ï¼ˆå½¢çŠ¶(b, h * w, 3)ï¼‰
        # target_scoresï¼šæ­£æ ·æœ¬çš„one - hotç±»åˆ«åˆ†æ•°ï¼ˆå½¢çŠ¶(b, h * w, num_classes)ï¼‰


    @staticmethod
    def select_candidates_in_gts(xy_centers, gt_circles, eps=1e-9):
        """Select positive anchor centers within ground truth bounding boxes.

        Args:
            xy_centers (torch.Tensor): Anchor center coordinates, shape (h*w, 2).
            gt_circles (torch.Tensor): Ground truth circles, shape (b, n_boxes, 3).
            eps (float, optional): Small value for numerical stability.

        Returns:
            (torch.Tensor): Boolean mask of positive anchors, shape (b, n_boxes, h*w).

        Notes:
            - b: batch size, n_boxes: number of ground truth boxes, h: height, w: width.
            - Bounding box format: [x_min, y_min, x_max, y_max].
        """
        n_anchors = xy_centers.shape[0] # 2550000
        bs, n_boxes, _ = gt_circles.shape # (8, max_objects, 3)
        xy, r = gt_circles.view(-1, 1, 3).split([2, 1], dim=2)  # center, radius
        diff = xy - xy_centers[None, :, :]  # (8*max_objects, 2550000, 2)
        r = r.view(-1, 1) # (8*max_objects, 1)
        distances = torch.norm(diff, dim=2)  # (8*max_objects, 2550000)
        return (distances <= r).view(bs, n_boxes, n_anchors).float()  # [8,max_objects,2550000] boolæ©ç 

        # bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors,
        #                                                                                     -1)  # è®¡ç®—é”šç‚¹ä¸çœŸå®æ¡†çš„åç§»é‡
        #return bbox_deltas.amin(3).gt_(eps)  # [8,max_objects,2550000] boolæ©ç 

    @staticmethod
    def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):
        """Select anchor boxes with highest IoU when assigned to multiple ground truths.

        Args:
            mask_pos (torch.Tensor): Positive mask, shape (b, n_max_boxes, h*w).
            overlaps (torch.Tensor): IoU overlaps, shape (b, n_max_boxes, h*w).
            n_max_boxes (int): Maximum number of ground truth boxes.

        Returns:
            target_gt_idx (torch.Tensor): Indices of assigned ground truths, shape (b, h*w).
            fg_mask (torch.Tensor): Foreground mask, shape (b, h*w).
            mask_pos (torch.Tensor): Updated positive mask, shape (b, n_max_boxes, h*w).
        """
        # Convert (b, n_max_boxes, h*w) -> (b, h*w)
        fg_mask = mask_pos.sum(-2)
        if fg_mask.max() > 1:  # one anchor is assigned to multiple gt_bboxes
            mask_multi_gts = (fg_mask.unsqueeze(1) > 1).expand(-1, n_max_boxes, -1)  # (b, n_max_boxes, h*w)
            max_overlaps_idx = overlaps.argmax(1)  # (b, h*w)

            is_max_overlaps = torch.zeros(mask_pos.shape, dtype=mask_pos.dtype, device=mask_pos.device)
            is_max_overlaps.scatter_(1, max_overlaps_idx.unsqueeze(1), 1)

            mask_pos = torch.where(mask_multi_gts, is_max_overlaps, mask_pos).float()  # (b, n_max_boxes, h*w)
            fg_mask = mask_pos.sum(-2)
        # Find each grid serve which gt(index)
        target_gt_idx = mask_pos.argmax(-2)  # (b, h*w)
        return target_gt_idx, fg_mask, mask_pos
        # ç›®æ ‡ç´¢å¼• target_gt_idx(b, h*w) ã€å‰æ™¯æ©ç  fg_mask(b, h*w)å’Œæ›´æ–°åçš„æ­£æ ·æœ¬æ©ç  mask_pose(b, n_max_boxes, h*w)ã€‚
        #target_gt_idx: æ¯ä¸ªé”šç‚¹å…·ä½“è´Ÿè´£ç¬¬å‡ ä¸ªç‰©ä½“ã€‚
        #fg_mask: å‰æ™¯æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº›é”šç‚¹æ˜¯æ­£æ ·æœ¬ã€‚
        #mask_pos: æ›´æ–°åçš„æ­£æ ·æœ¬æ©ç ï¼Œå½¢çŠ¶ä¸º (b, n_max_boxes, h*w)ï¼Œç”¨äºæŒ‡ç¤ºæ¯ä¸ªé”šç‚¹æ˜¯å¦è´Ÿè´£æŸä¸ªçœŸå®ç›®æ ‡ã€‚





def center_distanceLoss(self, gt_circles, pd_circles,na):
    """è®¡ç®—çœŸå®åœ†ä¸é¢„æµ‹åœ†çš„ä¸­å¿ƒè·ç¦»æŸå¤±

    Args:
        gt_circles (torch.Tensor): Ground truth circles with shape (bs*max_objects*2550000, 3).
        pd_circles (torch.Tensor): Predicted circles with shape (bs*max_objects*2550000, 3).

    Returns:
        center_distance_loss (torch.Tensor): Center distance loss between predicted and ground truth circles.
    """
    x1, y1, r1 = gt_circles.split(1, dim=1)  # (bs*max_objects*2550000, 1)
    x2, y2, r2 = pd_circles.split(1, dim=1)  # (bs*max_objects*2550000, 1)
    d = torch.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)  # (bs*max_objects*2550000, 1)
    r = r1 + r2  # (bs*max_objects*2550000, 1)
    distance = torch.clamp((r - d) / r, min=0)  # (bs*max_objects*2550000, 1)
    return distance.squeeze(1).view(self.bs, self.n_max_boxes, na)

def circle_ious(self, gt_circles, pd_circles,na):
    """
    ğŸš€ é—ªç”µä¾ çº§åœ†äº¤å¹¶æ¯”ï¼ˆIoUï¼‰è®¡ç®—ï¼ˆä¸“ä¸ºè¶…å¤§æ‰¹æ¬¡è®¾è®¡ï¼‰
    Args:
        gt_circles: (N, 3) -> [x, y, r] for ground truth
        pd_circles: (N, 3) -> [x, y, r] for predictions
        N = bs * max_objects * 2550000 (ä»»æ„å¤§å°)

    Returns:
        iou: (N,) IoU å€¼ (0~1)
    """
    # 1ï¸âƒ£ æå–åœ†å¿ƒå’ŒåŠå¾„ï¼ˆ0å¼€é”€åˆ‡ç‰‡ï¼‰
    c0 = gt_circles[:, :2]  # (N, 2)
    r0 = gt_circles[:, 2]  # (N,)
    c1 = pd_circles[:, :2]  # (N, 2)
    r1 = pd_circles[:, 2]  # (N,)
    # 2ï¸âƒ£ æ ¸å¿ƒï¼šé«˜æ•ˆè®¡ç®—äº¤é›†é¢ç§¯ï¼ˆå¤ç”¨ä¹‹å‰ä¼˜åŒ–ç‰ˆï¼‰
    inter_area = self.circle_intersection_area_tensor(c0, r0, c1, r1)
    # 3ï¸âƒ£ è®¡ç®—å¹¶é›†é¢ç§¯ = åœ†1é¢ç§¯ + åœ†2é¢ç§¯ - äº¤é›†é¢ç§¯
    area0 = torch.pi * r0 ** 2
    area1 = torch.pi * r1 ** 2
    union_area = area0 + area1 - inter_area
    # 4ï¸âƒ£ è®¡ç®— IoU (å®‰å…¨å¤„ç†é™¤ä»¥0)
    iou = inter_area / union_area
    iou = torch.where(union_area > 0, iou, torch.zeros_like(iou))
    return iou.view(self.bs, self.n_max_boxes, na)

def circle_intersection_area_tensor(self,c0, r0, c1, r1):
    """ï¼ˆåŒå‰ï¼Œå·²ä¼˜åŒ–åˆ°æ•ˆç‡å¤©èŠ±æ¿ï¼‰"""
    d = torch.linalg.norm(c0 - c1, dim=-1)
    no_inter = d >= r0 + r1
    contained = d <= torch.abs(r0 - r1)
    area = torch.zeros_like(d)

    # åŒ…å«æƒ…å†µï¼šå°åœ†é¢ç§¯
    area = torch.where(
        contained,
        torch.pi * torch.min(r0, r1) ** 2,
        area
    )

    # ä»…å¤„ç†ç›¸äº¤æ ·æœ¬ï¼ˆ95%+æ ·æœ¬ç›´æ¥è·³è¿‡ï¼ï¼‰
    mask = (~no_inter) & (~contained)
    if not mask.any():
        return area

    # ç²¾å‡†åˆ‡ç‰‡
    dm, r0m, r1m = d[mask], r0[mask], r1[mask]

    # é˜²æµ®ç‚¹è¯¯å·®
    t0 = (dm ** 2 + r0m ** 2 - r1m ** 2) / (2 * dm * r0m)
    t1 = (dm ** 2 + r1m ** 2 - r0m ** 2) / (2 * dm * r1m)
    t0, t1 = t0.clamp(-1.0, 1.0), t1.clamp(-1.0, 1.0)

    # æµ·ä¼¦å…¬å¼å®‰å…¨è®¡ç®—
    sq = torch.sqrt(torch.clamp(
        (-dm + r0m + r1m) * (dm + r0m - r1m) * (dm - r0m + r1m) * (dm + r0m + r1m),
        min=0.0
    ))

    # è®¡ç®—ç›¸äº¤é¢ç§¯
    area_m = r0m ** 2 * torch.acos(t0) + r1m ** 2 * torch.acos(t1) - 0.5 * sq
    area[mask] = area_m

    return area







def make_anchors(feats, strides, grid_cell_offset=0.5):
    """Generate anchors from features."""
    anchor_points, stride_tensor = [], []
    assert feats is not None
    dtype, device = feats[0].dtype, feats[0].device
    for i, stride in enumerate(strides):
        h, w = feats[i].shape[2:] if isinstance(feats, list) else (int(feats[i][0]), int(feats[i][1]))
        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x
        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y
        sy, sx = torch.meshgrid(sy, sx, indexing="ij")
        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))
        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))
    return torch.cat(anchor_points), torch.cat(stride_tensor)



def dist2circle(distance, anchor_points, dim=-1):
    """Transform distance(ltrb) to box(xywh or xyxy)."""
    l, r = distance.chunk(2, dim)
    t = l
    b = r
    lt = torch.cat((l, t), dim)
    rb = torch.cat((r, b), dim)
    x1y1 = anchor_points - lt # (8, 2550000, 2)
    x2y2 = anchor_points + rb # (8, 2550000, 2)
    xy = (x1y1 + x2y2) / 2
    r = (x2y2 - x1y1) / 2 # (8, 2550000, 2)
    r = torch.mean(r, dim=-1, keepdim=True) # (8, 2550000, 1)
    #rec = torch.cat((x1y1, x2y2), dim)

    return torch.cat((xy, r), dim)  # xyr circle
